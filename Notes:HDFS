Hadoop Distributed file system

Handles big files by having a large amount of storage. By disbursing the data across various nodes it can increase its volume and processing power. 
Its default is 128mb on how it splits up the data across different servers. Redundency factor 3 = Replication of 3.

Consistency -Gossip Protocol - Any updates made happens a lot faster. Tell other servers that it's being uddated.
Availability
Partition

Masternode is the the Name Node and the children is the Data Nodes.
Name node writes to local disk and NFS(NameNode File Sys). edit.log is update evertime name node changes hdd->->edit.log There also an image 
in case the primary name node fails 

								Resource manager - Yarn
Using HDFS
UI (Ambari)
CUI 
HTTP / HDFS Proxies
Java (Interface run Jar files or directly from code execusion)
	Client mode  -testing purpose
	Cluster mdoe -deployment - automation 
NFS


